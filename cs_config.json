{
    "======== MODEL ARGS ========": null,
    "pretrained_name": "hfl/chinese-roberta-wwm-ext",
    "tokenizer_name": null,
    "cache_dir": null,
    "ckpt_path": null,
    "======== DATA ARGS ========": null,
    "data_root": "/tmp2/b08902049/adl-hw2",
    "max_len": 512,
    "pad_to_max_len": true,
    "======== TRAINING ARGS ========": null,
    "seed": 777,
    "num_train_epochs": 5,
    "learning_rate": 1e-4,
    "weight_decay": 1e-6,
    "per_device_train_batch_size": 2,
    "per_valid_train_batch_size": 8,
    "gradient_accumulation_steps": 4,
    "output_dir": "/tmp2/b08902049/adl-hw2/output",
    "evaluation_strategy": "steps",
    "eval_steps": 1000,
    "logging_strategy": "steps",
    "logging_steps": 100,
    "logging_dir": null,
    "save_strategy": "epoch",
    "save_total_limit": 3
}